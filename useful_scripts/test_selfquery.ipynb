{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Structring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>did</th>\n",
       "      <th>name</th>\n",
       "      <th>version</th>\n",
       "      <th>uploader</th>\n",
       "      <th>status</th>\n",
       "      <th>format</th>\n",
       "      <th>MajorityClassSize</th>\n",
       "      <th>MaxNominalAttDistinctValues</th>\n",
       "      <th>MinorityClassSize</th>\n",
       "      <th>...</th>\n",
       "      <th>NumberOfFeatures</th>\n",
       "      <th>NumberOfInstances</th>\n",
       "      <th>NumberOfInstancesWithMissingValues</th>\n",
       "      <th>NumberOfMissingValues</th>\n",
       "      <th>NumberOfNumericFeatures</th>\n",
       "      <th>NumberOfSymbolicFeatures</th>\n",
       "      <th>description</th>\n",
       "      <th>qualities</th>\n",
       "      <th>features</th>\n",
       "      <th>Combined_information</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>anneal</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>684.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>898.0</td>\n",
       "      <td>898.0</td>\n",
       "      <td>22175.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>**Author**: Unknown. Donated by David Sterling...</td>\n",
       "      <td>AutoCorrelation : 0.6064659977703456, CfsSubse...</td>\n",
       "      <td>0 : [0 - family (nominal)], 1 : [1 - product-t...</td>\n",
       "      <td>did - 2, name - anneal, version - 1, uploader ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kr-vs-kp</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>1669.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1527.0</td>\n",
       "      <td>...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3196.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Author: Alen Shapiro\\nSource: [UCI](https://ar...</td>\n",
       "      <td>AutoCorrelation : 0.9990610328638497, CfsSubse...</td>\n",
       "      <td>0 : [0 - bkblk (nominal)], 1 : [1 - bknwy (nom...</td>\n",
       "      <td>did - 3, name - kr-vs-kp, version - 1, uploade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>labor</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>**Author**: Unknown\\n**Source**: Collective Ba...</td>\n",
       "      <td>AutoCorrelation : 0.75, CfsSubsetEval_Decision...</td>\n",
       "      <td>0 : [0 - duration (numeric)], 1 : [1 - wage-in...</td>\n",
       "      <td>did - 4, name - labor, version - 1, uploader -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>arrhythmia</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>245.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>280.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>**Author**: H. Altay Guvenir, Burak Acar, Hald...</td>\n",
       "      <td>AutoCorrelation : 0.35476718403547675, CfsSubs...</td>\n",
       "      <td>0 : [0 - age (numeric)], 1 : [1 - sex (nominal...</td>\n",
       "      <td>did - 5, name - arrhythmia, version - 1, uploa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>letter</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>813.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>734.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>**Author**: David J. Slate  \\n**Source**: [UCI...</td>\n",
       "      <td>AutoCorrelation : 0.04090204510225511, CfsSubs...</td>\n",
       "      <td>0 : [0 - x-box (numeric)], 1 : [1 - y-box (num...</td>\n",
       "      <td>did - 6, name - letter, version - 1, uploader ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  did        name  version  uploader  status format  \\\n",
       "0           0    2      anneal        1         1  active   ARFF   \n",
       "1           1    3    kr-vs-kp        1         1  active   ARFF   \n",
       "2           2    4       labor        1         1  active   ARFF   \n",
       "3           3    5  arrhythmia        1         1  active   ARFF   \n",
       "4           4    6      letter        1         1  active   ARFF   \n",
       "\n",
       "   MajorityClassSize  MaxNominalAttDistinctValues  MinorityClassSize  ...  \\\n",
       "0              684.0                          7.0                8.0  ...   \n",
       "1             1669.0                          3.0             1527.0  ...   \n",
       "2               37.0                          3.0               20.0  ...   \n",
       "3              245.0                         13.0                2.0  ...   \n",
       "4              813.0                         26.0              734.0  ...   \n",
       "\n",
       "   NumberOfFeatures  NumberOfInstances  NumberOfInstancesWithMissingValues  \\\n",
       "0              39.0              898.0                               898.0   \n",
       "1              37.0             3196.0                                 0.0   \n",
       "2              17.0               57.0                                56.0   \n",
       "3             280.0              452.0                               384.0   \n",
       "4              17.0            20000.0                                 0.0   \n",
       "\n",
       "   NumberOfMissingValues  NumberOfNumericFeatures  NumberOfSymbolicFeatures  \\\n",
       "0                22175.0                      6.0                      33.0   \n",
       "1                    0.0                      0.0                      37.0   \n",
       "2                  326.0                      8.0                       9.0   \n",
       "3                  408.0                    206.0                      74.0   \n",
       "4                    0.0                     16.0                       1.0   \n",
       "\n",
       "                                         description  \\\n",
       "0  **Author**: Unknown. Donated by David Sterling...   \n",
       "1  Author: Alen Shapiro\\nSource: [UCI](https://ar...   \n",
       "2  **Author**: Unknown\\n**Source**: Collective Ba...   \n",
       "3  **Author**: H. Altay Guvenir, Burak Acar, Hald...   \n",
       "4  **Author**: David J. Slate  \\n**Source**: [UCI...   \n",
       "\n",
       "                                           qualities  \\\n",
       "0  AutoCorrelation : 0.6064659977703456, CfsSubse...   \n",
       "1  AutoCorrelation : 0.9990610328638497, CfsSubse...   \n",
       "2  AutoCorrelation : 0.75, CfsSubsetEval_Decision...   \n",
       "3  AutoCorrelation : 0.35476718403547675, CfsSubs...   \n",
       "4  AutoCorrelation : 0.04090204510225511, CfsSubs...   \n",
       "\n",
       "                                            features  \\\n",
       "0  0 : [0 - family (nominal)], 1 : [1 - product-t...   \n",
       "1  0 : [0 - bkblk (nominal)], 1 : [1 - bknwy (nom...   \n",
       "2  0 : [0 - duration (numeric)], 1 : [1 - wage-in...   \n",
       "3  0 : [0 - age (numeric)], 1 : [1 - sex (nominal...   \n",
       "4  0 : [0 - x-box (numeric)], 1 : [1 - y-box (num...   \n",
       "\n",
       "                                Combined_information  \n",
       "0  did - 2, name - anneal, version - 1, uploader ...  \n",
       "1  did - 3, name - kr-vs-kp, version - 1, uploade...  \n",
       "2  did - 4, name - labor, version - 1, uploader -...  \n",
       "3  did - 5, name - arrhythmia, version - 1, uploa...  \n",
       "4  did - 6, name - letter, version - 1, uploader ...  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"~/Downloads/all_dataset_description.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'did', 'name', 'version', 'uploader', 'status', 'format',\n",
      "       'MajorityClassSize', 'MaxNominalAttDistinctValues', 'MinorityClassSize',\n",
      "       'NumberOfClasses', 'NumberOfFeatures', 'NumberOfInstances',\n",
      "       'NumberOfInstancesWithMissingValues', 'NumberOfMissingValues',\n",
      "       'NumberOfNumericFeatures', 'NumberOfSymbolicFeatures', 'description',\n",
      "       'qualities', 'features', 'Combined_information'],\n",
      "      dtype='object')\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)\n",
    "print(len(data.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using LLM to define each attribute instead of writing manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model = ChatOpenAI(model=\"gpt-4\", api_key=\"\")\n",
    "# res = model.predict(\n",
    "#     \"Below is a table with information about metadata of machine learning datasets.\"\n",
    "#     \"Return a JSON list with an entry for each column. Each entry should have \"\n",
    "#     '{\"name\": \"column name\", \"description\": \"column description\", \"type\": \"column data type\"}'\n",
    "#     f\"\\n\\n{data.head()}\\n\\nJSON:\\n\"\n",
    "# )\n",
    "\n",
    "# import json\n",
    "\n",
    "# attribute_info = json.loads(res)\n",
    "# print(len(attribute_info))\n",
    "# attribute_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attribute_info[3][\"description\"] = \"Version of this dataset. '1' for original version. Auto-incremented by server.\"\n",
    "# attribute_info[5][\"description\"] = \"Current status of the dataset. Whether the dataset is active.\"\n",
    "# attribute_info[6][\"description\"] = \"Format of the dataset. Example - arff format \"\n",
    "# attribute_info[7][\"description\"] = \"Number of instances belonging to the most frequent class.\"\n",
    "# attribute_info[8][\"description\"] = \"The maximum number of distinct values among attributes of the nominal type.\"\n",
    "# attribute_info[9][\"description\"] = \"Number of instances belonging to the least frequent class.\"\n",
    "# attribute_info[10][\"description\"] = \"Number of classes in the dataset. 2.0 for binary classification, and more than 2.0 for multi-class classification.\"\n",
    "# attribute_info[11][\"description\"] = \"Number of features or attributes in the dataset.\"\n",
    "# attribute_info[20][\"description\"] = \"Combine information from all the coulmns in the dataset.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open('../data/attribute_info.json', 'w') as f:\n",
    "#     json.dump(attribute_info,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "{'name': 'did', 'description': 'Dataset ID', 'type': 'Numeric'}\n",
      "{'name': 'name', 'description': 'Name of the dataset', 'type': 'String'}\n",
      "{'name': 'version', 'description': \"Version of this dataset. '1' for original version. Auto-incremented by server.\", 'type': 'Numeric'}\n",
      "{'name': 'uploader', 'description': 'ID of the uploader', 'type': 'Numeric'}\n",
      "{'name': 'status', 'description': 'Current status of the dataset. Whether the dataset is active.', 'type': 'String'}\n",
      "{'name': 'format', 'description': 'Format of the dataset. Example - arff format ', 'type': 'String'}\n",
      "{'name': 'MajorityClassSize', 'description': 'Number of instances belonging to the most frequent class.', 'type': 'Numeric'}\n",
      "{'name': 'MaxNominalAttDistinctValues', 'description': 'The maximum number of distinct values among attributes of the nominal type.', 'type': 'Numeric'}\n",
      "{'name': 'MinorityClassSize', 'description': 'Number of instances belonging to the least frequent class.', 'type': 'Numeric'}\n",
      "{'name': 'NumberOfClasses', 'description': 'Number of classes in the dataset. 2.0 for binary classification, and more than 2.0 for multi-class classification.', 'type': 'Numeric'}\n",
      "{'name': 'NumberOfFeatures', 'description': 'Number of features or attributes in the dataset.', 'type': 'Numeric'}\n",
      "{'name': 'NumberOfInstances', 'description': 'Number of instances in the dataset', 'type': 'Numeric'}\n",
      "{'name': 'NumberOfInstancesWithMissingValues', 'description': 'Number of instances with missing values in the dataset', 'type': 'Numeric'}\n",
      "{'name': 'NumberOfMissingValues', 'description': 'Number of missing values in the dataset', 'type': 'Numeric'}\n",
      "{'name': 'NumberOfNumericFeatures', 'description': 'Number of numeric features in the dataset', 'type': 'Numeric'}\n",
      "{'name': 'NumberOfSymbolicFeatures', 'description': 'Number of symbolic features in the dataset', 'type': 'Numeric'}\n",
      "{'name': 'description', 'description': 'Description of the dataset', 'type': 'String'}\n",
      "{'name': 'qualities', 'description': 'Qualities of the dataset', 'type': 'String'}\n",
      "{'name': 'features', 'description': 'Features of the dataset', 'type': 'String'}\n",
      "{'name': 'Combined_information', 'description': 'Combine information from all the coulmns in the dataset.', 'type': 'String'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../data/attribute_info.json\", \"r\") as f:\n",
    "    attribute_info = json.loads(f.read())\n",
    "\n",
    "attribute_info = attribute_info[1:]\n",
    "print(len(attribute_info))\n",
    "print(*attribute_info, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strctured-Query Construction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.query_constructor.base import (\n",
    "    get_query_constructor_prompt,\n",
    "    load_query_constructor_runnable,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    (\n",
    "        \"Give me mushroom datasets with less than 10k rows.\",\n",
    "        {\n",
    "            \"query\": \"mushroom dataset\",\n",
    "            \"filter\": 'lt(\"NumberOfInstances\", 10000)',\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"Give me datasets than can be used in healthcare with 2 or more classes\",\n",
    "        {\n",
    "            \"query\": \"heathcare dataset \",\n",
    "            \"filter\": 'gte(\"NumberOfClasses\", 2.0)',\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"Give me datasets than can be used in healthcare, or climate applications with 2 or more classes and in arff format.\",\n",
    "        {\n",
    "            \"query\": \"heathcare dataset, climate datasets\",\n",
    "            \"filter\": 'and(gte(\"NumberOfClasses\", 2.0), eq(\"format\", \"arff\"))',\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"Give me medical datasets.\",\n",
    "        {\n",
    "            \"query\": \"medical datasets\",\n",
    "            \"filter\": \"NO_FILTER\",\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"Give me medical datasets with large number of features.\",\n",
    "        {\n",
    "            \"query\": \"medical datasets\",\n",
    "            \"filter\": 'gte(\"NumberOfFeatures, 100)',\n",
    "        },\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your goal is to structure the user's query to match the request schema provided below.\n",
      "\n",
      "<< Structured Request Schema >>\n",
      "When responding use a markdown code snippet with a JSON object formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"query\": string \\ text string to compare to document contents\n",
      "    \"filter\": string \\ logical condition statement for filtering documents\n",
      "}\n",
      "```\n",
      "\n",
      "The query string should contain only text that is expected to match the contents of documents. Any conditions in the filter should not be mentioned in the query as well.\n",
      "\n",
      "A logical condition statement is composed of one or more comparison and logical operation statements.\n",
      "\n",
      "A comparison statement takes the form: `comp(attr, val)`:\n",
      "- `comp` (eq | ne | gt | gte | lt | lte | contain | like | in | nin): comparator\n",
      "- `attr` (string):  name of attribute to apply the comparison to\n",
      "- `val` (string): is the comparison value\n",
      "\n",
      "A logical operation statement takes the form `op(statement1, statement2, ...)`:\n",
      "- `op` (and | or | not): logical operator\n",
      "- `statement1`, `statement2`, ... (comparison statements or logical operation statements): one or more statements to apply the operation to\n",
      "\n",
      "Make sure that you only use the comparators and logical operators listed above and no others.\n",
      "Make sure that filters only refer to attributes that exist in the data source.\n",
      "Make sure that filters only use the attributed names with its function names if there are functions applied on them.\n",
      "Make sure that filters only use format `YYYY-MM-DD` when handling date data typed values.\n",
      "Make sure that filters take into account the descriptions of attributes and only make comparisons that are feasible given the type of data being stored.\n",
      "Make sure that filters are only used as needed. If there are no filters that should be applied return \"NO_FILTER\" for the filter value.\n",
      "\n",
      "<< Data Source >>\n",
      "```json\n",
      "{\n",
      "    \"content\": \"Metadata of datasets for various machine learning applications fetched from OpenML platform\",\n",
      "    \"attributes\": {\n",
      "    \"did\": {\n",
      "        \"description\": \"Dataset ID\",\n",
      "        \"type\": \"Numeric\"\n",
      "    },\n",
      "    \"name\": {\n",
      "        \"description\": \"Name of the dataset\",\n",
      "        \"type\": \"String\"\n",
      "    },\n",
      "    \"version\": {\n",
      "        \"description\": \"Version of this dataset. '1' for original version. Auto-incremented by server.\",\n",
      "        \"type\": \"Numeric\"\n",
      "    },\n",
      "    \"uploader\": {\n",
      "        \"description\": \"ID of the uploader\",\n",
      "        \"type\": \"Numeric\"\n",
      "    },\n",
      "    \"status\": {\n",
      "        \"description\": \"Current status of the dataset. Whether the dataset is active.\",\n",
      "        \"type\": \"String\"\n",
      "    },\n",
      "    \"format\": {\n",
      "        \"description\": \"Format of the dataset. Example - arff format \",\n",
      "        \"type\": \"String\"\n",
      "    },\n",
      "    \"MajorityClassSize\": {\n",
      "        \"description\": \"Number of instances belonging to the most frequent class.\",\n",
      "        \"type\": \"Numeric\"\n",
      "    },\n",
      "    \"MaxNominalAttDistinctValues\": {\n",
      "        \"description\": \"The maximum number of distinct values among attributes of the nominal type.\",\n",
      "        \"type\": \"Numeric\"\n",
      "    },\n",
      "    \"MinorityClassSize\": {\n",
      "        \"description\": \"Number of instances belonging to the least frequent class.\",\n",
      "        \"type\": \"Numeric\"\n",
      "    },\n",
      "    \"NumberOfClasses\": {\n",
      "        \"description\": \"Number of classes in the dataset. 2.0 for binary classification, and more than 2.0 for multi-class classification.\",\n",
      "        \"type\": \"Numeric\"\n",
      "    },\n",
      "    \"NumberOfFeatures\": {\n",
      "        \"description\": \"Number of features or attributes in the dataset.\",\n",
      "        \"type\": \"Numeric\"\n",
      "    },\n",
      "    \"NumberOfInstances\": {\n",
      "        \"description\": \"Number of instances in the dataset\",\n",
      "        \"type\": \"Numeric\"\n",
      "    },\n",
      "    \"NumberOfInstancesWithMissingValues\": {\n",
      "        \"description\": \"Number of instances with missing values in the dataset\",\n",
      "        \"type\": \"Numeric\"\n",
      "    },\n",
      "    \"NumberOfMissingValues\": {\n",
      "        \"description\": \"Number of missing values in the dataset\",\n",
      "        \"type\": \"Numeric\"\n",
      "    },\n",
      "    \"NumberOfNumericFeatures\": {\n",
      "        \"description\": \"Number of numeric features in the dataset\",\n",
      "        \"type\": \"Numeric\"\n",
      "    },\n",
      "    \"NumberOfSymbolicFeatures\": {\n",
      "        \"description\": \"Number of symbolic features in the dataset\",\n",
      "        \"type\": \"Numeric\"\n",
      "    },\n",
      "    \"description\": {\n",
      "        \"description\": \"Description of the dataset\",\n",
      "        \"type\": \"String\"\n",
      "    },\n",
      "    \"qualities\": {\n",
      "        \"description\": \"Qualities of the dataset\",\n",
      "        \"type\": \"String\"\n",
      "    },\n",
      "    \"features\": {\n",
      "        \"description\": \"Features of the dataset\",\n",
      "        \"type\": \"String\"\n",
      "    },\n",
      "    \"Combined_information\": {\n",
      "        \"description\": \"Combine information from all the coulmns in the dataset.\",\n",
      "        \"type\": \"String\"\n",
      "    }\n",
      "}\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "<< Example 1. >>\n",
      "User Query:\n",
      "Give me mushroom datasets with less than 10k rows.\n",
      "\n",
      "Structured Request:\n",
      "```json\n",
      "{\n",
      "    \"query\": \"mushroom dataset\",\n",
      "    \"filter\": \"lt(\\\"NumberOfInstances\\\", 10000)\"\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "<< Example 2. >>\n",
      "User Query:\n",
      "Give me datasets than can be used in healthcare with 2 or more classes\n",
      "\n",
      "Structured Request:\n",
      "```json\n",
      "{\n",
      "    \"query\": \"heathcare dataset \",\n",
      "    \"filter\": \"gte(\\\"NumberOfClasses\\\", 2.0)\"\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "<< Example 3. >>\n",
      "User Query:\n",
      "Give me datasets than can be used in healthcare, or climate applications with 2 or more classes and in arff format.\n",
      "\n",
      "Structured Request:\n",
      "```json\n",
      "{\n",
      "    \"query\": \"heathcare dataset, climate datasets\",\n",
      "    \"filter\": \"and(gte(\\\"NumberOfClasses\\\", 2.0), eq(\\\"format\\\", \\\"arff\\\"))\"\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "<< Example 4. >>\n",
      "User Query:\n",
      "Give me medical datasets.\n",
      "\n",
      "Structured Request:\n",
      "```json\n",
      "{\n",
      "    \"query\": \"medical datasets\",\n",
      "    \"filter\": \"NO_FILTER\"\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "<< Example 5. >>\n",
      "User Query:\n",
      "Give me medical datasets with large number of features.\n",
      "\n",
      "Structured Request:\n",
      "```json\n",
      "{\n",
      "    \"query\": \"medical datasets\",\n",
      "    \"filter\": \"gte(\\\"NumberOfFeatures, 100)\"\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "<< Example 6. >>\n",
      "User Query:\n",
      "{query}\n",
      "\n",
      "Structured Request:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "document_content_description = \"Metadata of datasets for various machine learning applications fetched from OpenML platform\"\n",
    "prompt = get_query_constructor_prompt(\n",
    "    document_contents=document_content_description,\n",
    "    attribute_info=attribute_info,\n",
    "    examples=examples,\n",
    ")\n",
    "print(prompt.format(query=\"{query}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limiting number of attributes fileds to filter upon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'name': 'status',\n",
       "  'description': 'Current status of the dataset. Whether the dataset is active.',\n",
       "  'type': 'String'},\n",
       " {'name': 'NumberOfClasses',\n",
       "  'description': 'Number of classes in the dataset. 2.0 for binary classification, and more than 2.0 for multi-class classification.',\n",
       "  'type': 'Numeric'},\n",
       " {'name': 'NumberOfFeatures',\n",
       "  'description': 'Number of features or attributes in the dataset.',\n",
       "  'type': 'Numeric'},\n",
       " {'name': 'NumberOfInstances',\n",
       "  'description': 'Number of instances in the dataset',\n",
       "  'type': 'Numeric'},\n",
       " {'name': 'Combined_information',\n",
       "  'description': 'Combine information from all the coulmns in the dataset.',\n",
       "  'type': 'String'})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "content_attr = [\n",
    "    \"status\",\n",
    "    \"NumberOfClasses\",\n",
    "    \"NumberOfFeatures\",\n",
    "    \"NumberOfInstances\",\n",
    "    \"Combined_information\",\n",
    "]\n",
    "# document_content_description = \"Metadata of machine learning datasets including status (if dataset is active or not), number of classes in the dataset, number of instances (examples) in the dataset, number of features in the dataset, and Combined_information containing the combined metadata information about the dataset.\"\n",
    "filter_attribute_info = tuple(ai for ai in attribute_info if ai[\"name\"] in content_attr)\n",
    "\n",
    "filter_attribute_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_query_constructor_runnable(\n",
    "    ChatOllama(model=\"llama3\"),\n",
    "    document_content_description,\n",
    "    # attribute_info,\n",
    "    filter_attribute_info,\n",
    "    examples=examples,\n",
    "    fix_invalid=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Runnable.get_prompts of FewShotPromptTemplate(input_variables=['query'], examples=[{'i': 1, 'user_query': 'Give me mushroom datasets with less than 10k rows.', 'structured_request': '{{\\n    \"query\": \"mushroom dataset\",\\n    \"filter\": \"lt(\\\\\"NumberOfInstances\\\\\", 10000)\"\\n}}'}, {'i': 2, 'user_query': 'Give me datasets than can be used in healthcare with 2 or more classes', 'structured_request': '{{\\n    \"query\": \"heathcare dataset \",\\n    \"filter\": \"gte(\\\\\"NumberOfClasses\\\\\", 2.0)\"\\n}}'}, {'i': 3, 'user_query': 'Give me datasets than can be used in healthcare, or climate applications with 2 or more classes and in arff format.', 'structured_request': '{{\\n    \"query\": \"heathcare dataset, climate datasets\",\\n    \"filter\": \"and(gte(\\\\\"NumberOfClasses\\\\\", 2.0), eq(\\\\\"format\\\\\", \\\\\"arff\\\\\"))\"\\n}}'}, {'i': 4, 'user_query': 'Give me medical datasets.', 'structured_request': '{{\\n    \"query\": \"medical datasets\",\\n    \"filter\": \"NO_FILTER\"\\n}}'}, {'i': 5, 'user_query': 'Give me medical datasets with large number of features.', 'structured_request': '{{\\n    \"query\": \"medical datasets\",\\n    \"filter\": \"gte(\\\\\"NumberOfFeatures, 100)\"\\n}}'}], example_prompt=PromptTemplate(input_variables=['i', 'structured_request', 'user_query'], template='<< Example {i}. >>\\nUser Query:\\n{user_query}\\n\\nStructured Request:\\n```json\\n{structured_request}\\n```\\n'), suffix='<< Example 6. >>\\nUser Query:\\n{query}\\n\\nStructured Request:\\n', prefix='Your goal is to structure the user\\'s query to match the request schema provided below.\\n\\n<< Structured Request Schema >>\\nWhen responding use a markdown code snippet with a JSON object formatted in the following schema:\\n\\n```json\\n{{\\n    \"query\": string \\\\ text string to compare to document contents\\n    \"filter\": string \\\\ logical condition statement for filtering documents\\n}}\\n```\\n\\nThe query string should contain only text that is expected to match the contents of documents. Any conditions in the filter should not be mentioned in the query as well.\\n\\nA logical condition statement is composed of one or more comparison and logical operation statements.\\n\\nA comparison statement takes the form: `comp(attr, val)`:\\n- `comp` (eq | ne | gt | gte | lt | lte | contain | like | in | nin): comparator\\n- `attr` (string):  name of attribute to apply the comparison to\\n- `val` (string): is the comparison value\\n\\nA logical operation statement takes the form `op(statement1, statement2, ...)`:\\n- `op` (and | or | not): logical operator\\n- `statement1`, `statement2`, ... (comparison statements or logical operation statements): one or more statements to apply the operation to\\n\\nMake sure that you only use the comparators and logical operators listed above and no others.\\nMake sure that filters only refer to attributes that exist in the data source.\\nMake sure that filters only use the attributed names with its function names if there are functions applied on them.\\nMake sure that filters only use format `YYYY-MM-DD` when handling date data typed values.\\nMake sure that filters take into account the descriptions of attributes and only make comparisons that are feasible given the type of data being stored.\\nMake sure that filters are only used as needed. If there are no filters that should be applied return \"NO_FILTER\" for the filter value.\\n\\n<< Data Source >>\\n```json\\n{{\\n    \"content\": \"Metadata of datasets for various machine learning applications fetched from OpenML platform\",\\n    \"attributes\": {{\\n    \"status\": {{\\n        \"description\": \"Current status of the dataset. Whether the dataset is active.\",\\n        \"type\": \"String\"\\n    }},\\n    \"NumberOfClasses\": {{\\n        \"description\": \"Number of classes in the dataset. 2.0 for binary classification, and more than 2.0 for multi-class classification.\",\\n        \"type\": \"Numeric\"\\n    }},\\n    \"NumberOfFeatures\": {{\\n        \"description\": \"Number of features or attributes in the dataset.\",\\n        \"type\": \"Numeric\"\\n    }},\\n    \"NumberOfInstances\": {{\\n        \"description\": \"Number of instances in the dataset\",\\n        \"type\": \"Numeric\"\\n    }},\\n    \"Combined_information\": {{\\n        \"description\": \"Combine information from all the coulmns in the dataset.\",\\n        \"type\": \"String\"\\n    }}\\n}}\\n}}\\n```\\n')\n",
       "| ChatOllama(model='llama3')\n",
       "| StructuredQueryOutputParser(ast_parse=<function StructuredQueryOutputParser.from_components.<locals>.ast_parse at 0x74aab3f953a0>)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.get_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Runnable.get_prompts of FewShotPromptTemplate(input_variables=['query'], examples=[{'i': 1, 'user_query': 'Give me mushroom datasets with less than 10k rows.', 'structured_request': '{{\\n    \"query\": \"mushroom dataset\",\\n    \"filter\": \"lt(\\\\\"NumberOfInstances\\\\\", 10000)\"\\n}}'}, {'i': 2, 'user_query': 'Give me datasets than can be used in healthcare with 2 or more classes', 'structured_request': '{{\\n    \"query\": \"heathcare dataset \",\\n    \"filter\": \"gte(\\\\\"NumberOfClasses\\\\\", 2.0)\"\\n}}'}, {'i': 3, 'user_query': 'Give me datasets than can be used in healthcare, or climate applications with 2 or more classes and in arff format.', 'structured_request': '{{\\n    \"query\": \"heathcare dataset, climate datasets\",\\n    \"filter\": \"and(gte(\\\\\"NumberOfClasses\\\\\", 2.0), eq(\\\\\"format\\\\\", \\\\\"arff\\\\\"))\"\\n}}'}, {'i': 4, 'user_query': 'Give me medical datasets.', 'structured_request': '{{\\n    \"query\": \"medical datasets\",\\n    \"filter\": \"NO_FILTER\"\\n}}'}, {'i': 5, 'user_query': 'Give me medical datasets with large number of features.', 'structured_request': '{{\\n    \"query\": \"medical datasets\",\\n    \"filter\": \"gte(\\\\\"NumberOfFeatures, 100)\"\\n}}'}], example_prompt=PromptTemplate(input_variables=['i', 'structured_request', 'user_query'], template='<< Example {i}. >>\\nUser Query:\\n{user_query}\\n\\nStructured Request:\\n```json\\n{structured_request}\\n```\\n'), suffix='<< Example 6. >>\\nUser Query:\\n{query}\\n\\nStructured Request:\\n', prefix='Your goal is to structure the user\\'s query to match the request schema provided below.\\n\\nDonot produce anything except json output using given schema.\\n\\n<< Data Source >>\\n```json\\n{{\\n    \"content\": \"Metadata of datasets for various machine learning applications fetched from OpenML platform\",\\n    \"attributes\": {{\\n    \"status\": {{\\n        \"description\": \"Current status of the dataset. Whether the dataset is active.\",\\n        \"type\": \"String\"\\n    }},\\n    \"NumberOfClasses\": {{\\n        \"description\": \"Number of classes in the dataset. 2.0 for binary classification, and more than 2.0 for multi-class classification.\",\\n        \"type\": \"Numeric\"\\n    }},\\n    \"NumberOfFeatures\": {{\\n        \"description\": \"Number of features or attributes in the dataset.\",\\n        \"type\": \"Numeric\"\\n    }},\\n    \"NumberOfInstances\": {{\\n        \"description\": \"Number of instances in the dataset\",\\n        \"type\": \"Numeric\"\\n    }},\\n    \"Combined_information\": {{\\n        \"description\": \"Combine information from all the coulmns in the dataset.\",\\n        \"type\": \"String\"\\n    }}\\n}}\\n}}\\n```\\n')\n",
       "| ChatOllama(model='llama3.1')\n",
       "| StructuredQueryOutputParser(ast_parse=<function StructuredQueryOutputParser.from_components.<locals>.ast_parse at 0x74aab8e3fe20>)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.get_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Please find climate or bird image datasets with less than 100 classes and in json format.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operator=<Operator.OR: 'or'> arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='Combined_information', value='climate dataset'), Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='Combined_information', value='bird image dataset')]\n",
      "operator=<Operator.AND: 'and'> arguments=[Operation(operator=<Operator.OR: 'or'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='Combined_information', value='climate dataset'), Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='Combined_information', value='bird image dataset')]), Comparison(comparator=<Comparator.LT: 'lt'>, attribute='NumberOfClasses', value=100), Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='format', value='json')]\n"
     ]
    },
    {
     "ename": "OutputParserException",
     "evalue": "Parsing text\nHere is the structured request for the user query:\n\n```\n{\n    \"query\": \"climate or bird image datasets\",\n    \"filter\": \"and(or(eq(\\\"Combined_information\\\", \\\"climate dataset\\\"), eq(\\\"Combined_information\\\", \\\"bird image dataset\\\")), lt(\\\"NumberOfClasses\\\", 100), eq(\\\"format\\\", \\\"json\\\"))\"\n}\n```\n raised following error:\n1 validation error for Operation\narguments -> 2\n  none is not an allowed value (type=type_error.none.not_allowed)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/ai_search/.venv/lib/python3.12/site-packages/langchain/chains/query_constructor/base.py:57\u001b[0m, in \u001b[0;36mStructuredQueryOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     parsed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilter\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mast_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfilter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parsed\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlimit\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Documents/ai_search/.venv/lib/python3.12/site-packages/langchain/chains/query_constructor/base.py:91\u001b[0m, in \u001b[0;36mStructuredQueryOutputParser.from_components.<locals>.ast_parse\u001b[0;34m(raw_filter)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mfilter\u001b[39m \u001b[38;5;241m=\u001b[39m cast(Optional[FilterDirective], get_parser()\u001b[38;5;241m.\u001b[39mparse(raw_filter))\n\u001b[0;32m---> 91\u001b[0m fixed \u001b[38;5;241m=\u001b[39m \u001b[43mfix_filter_directive\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallowed_comparators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_comparators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallowed_operators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_operators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallowed_attributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fixed\n",
      "File \u001b[0;32m~/Documents/ai_search/.venv/lib/python3.12/site-packages/langchain/chains/query_constructor/base.py:159\u001b[0m, in \u001b[0;36mfix_filter_directive\u001b[0;34m(filter, allowed_comparators, allowed_operators, allowed_attributes)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mfilter\u001b[39m)\n\u001b[0;32m--> 159\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m            \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m            \u001b[49m\u001b[43marguments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/ai_search/.venv/lib/python3.12/site-packages/langchain_core/structured_query.py:149\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[0;34m(self, operator, arguments, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m, operator: Operator, arguments: List[FilterDirective], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m    148\u001b[0m ):\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marguments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marguments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ai_search/.venv/lib/python3.12/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for Operation\narguments -> 2\n  none is not an allowed value (type=type_error.none.not_allowed)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m structured_query \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ai_search/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:2878\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2876\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2877\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2878\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2879\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2880\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/ai_search/.venv/lib/python3.12/site-packages/langchain_core/output_parsers/base.py:183\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mstr\u001b[39m, BaseMessage], config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    181\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[0;32m--> 183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m    193\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result([Generation(text\u001b[38;5;241m=\u001b[39minner_input)]),\n\u001b[1;32m    194\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    195\u001b[0m             config,\n\u001b[1;32m    196\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    197\u001b[0m         )\n",
      "File \u001b[0;32m~/Documents/ai_search/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:1785\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1782\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m   1783\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1784\u001b[0m         Output,\n\u001b[0;32m-> 1785\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1786\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1787\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1788\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1789\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1791\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1792\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1793\u001b[0m     )\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1795\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/Documents/ai_search/.venv/lib/python3.12/site-packages/langchain_core/runnables/config.py:427\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    426\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ai_search/.venv/lib/python3.12/site-packages/langchain_core/output_parsers/base.py:184\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke.<locals>.<lambda>\u001b[0;34m(inner_input)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mstr\u001b[39m, BaseMessage], config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    181\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m--> 184\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    187\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    188\u001b[0m             config,\n\u001b[1;32m    189\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    190\u001b[0m         )\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m    193\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result([Generation(text\u001b[38;5;241m=\u001b[39minner_input)]),\n\u001b[1;32m    194\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    195\u001b[0m             config,\n\u001b[1;32m    196\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    197\u001b[0m         )\n",
      "File \u001b[0;32m~/Documents/ai_search/.venv/lib/python3.12/site-packages/langchain_core/output_parsers/base.py:237\u001b[0m, in \u001b[0;36mBaseOutputParser.parse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_result\u001b[39m(\u001b[38;5;28mself\u001b[39m, result: List[Generation], \u001b[38;5;241m*\u001b[39m, partial: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    223\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Parse a list of candidate model Generations into a specific format.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03m    The return value is parsed from only the first Generation in the result, which\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;124;03m        Structured output.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ai_search/.venv/lib/python3.12/site-packages/langchain/chains/query_constructor/base.py:64\u001b[0m, in \u001b[0;36mStructuredQueryOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m StructuredQuery(\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m parsed\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m allowed_keys}\n\u001b[1;32m     62\u001b[0m     )\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParsing text\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m raised following error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m     )\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Parsing text\nHere is the structured request for the user query:\n\n```\n{\n    \"query\": \"climate or bird image datasets\",\n    \"filter\": \"and(or(eq(\\\"Combined_information\\\", \\\"climate dataset\\\"), eq(\\\"Combined_information\\\", \\\"bird image dataset\\\")), lt(\\\"NumberOfClasses\\\", 100), eq(\\\"format\\\", \\\"json\\\"))\"\n}\n```\n raised following error:\n1 validation error for Operation\narguments -> 2\n  none is not an allowed value (type=type_error.none.not_allowed)"
     ]
    }
   ],
   "source": [
    "structured_query = chain.invoke(\n",
    "        {\"query\": query}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredQuery(query='mushroom dataset', filter=Comparison(comparator=<Comparator.LT: 'lt'>, attribute='NumberOfInstances', value=10000), limit=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operator=<Operator.OR: 'or'> arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='Combined_information', value='climate dataset'), Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='Combined_information', value='bird image dataset')]\n",
      "operator=<Operator.AND: 'and'> arguments=[Operation(operator=<Operator.OR: 'or'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='Combined_information', value='climate dataset'), Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='Combined_information', value='bird image dataset')]), Comparison(comparator=<Comparator.LT: 'lt'>, attribute='NumberOfClasses', value=100)]\n",
      "operator=<Operator.AND: 'and'> arguments=[Operation(operator=<Operator.AND: 'and'>, arguments=[Operation(operator=<Operator.OR: 'or'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='Combined_information', value='climate dataset'), Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='Combined_information', value='bird image dataset')]), Comparison(comparator=<Comparator.LT: 'lt'>, attribute='NumberOfClasses', value=100)]), Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='format', value='json')]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    structured_query = chain.invoke(\n",
    "        {\"query\": query}\n",
    "    )\n",
    "    print(structured_query)\n",
    "except Exception as e:\n",
    "    error = e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.exceptions.OutputParserException('Parsing text\\nHere is the structured request for the user query:\\n\\n```json\\n{\\n    \"query\": \"climate or bird image datasets\",\\n    \"filter\": \"and(and(or(eq(\\\\\"Combined_information\\\\\", \\\\\"climate dataset\\\\\"), eq(\\\\\"Combined_information\\\\\", \\\\\"bird image dataset\\\\\")), lt(\\\\\"NumberOfClasses\\\\\", 100)), eq(\\\\\"format\\\\\", \\\\\"json\\\\\"))\"\\n}\\n```\\n\\nNote: I assumed that the combined information attribute contains keywords related to climate and bird image datasets. If this is not correct, please provide more context or clarify how this attribute should be used in filtering.\\n raised following error:\\n1 validation error for Operation\\narguments -> 1\\n  none is not an allowed value (type=type_error.none.not_allowed)')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_query = chain.invoke(\n",
    "    {\"query\": \"Find a mushroom dataset with less than 10k size\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Query:  mushroom dataset\n",
      "Filter(s):  comparator=<Comparator.LT: 'lt'> attribute='NumberOfInstances' value=10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Search Query: \", structured_query.query)\n",
    "print(\"Filter(s): \", structured_query.filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"query\": \"Find a mushroom dataset.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredQuery(query='medical dataset which has active status', filter=Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='status', value='active'), limit=None)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"query\": \"Find a medical dataset which has active status\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredQuery(query='mushroom dataset with large number of features', filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='status', value='active'), Comparison(comparator=<Comparator.GTE: 'gte'>, attribute='NumberOfFeatures', value=100)]), limit=None)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"query\": \"Find a mushroom dataset with large number of features\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredQuery(query='big mushroom dataset', filter=Comparison(comparator=<Comparator.GT: 'gt'>, attribute='NumberOfInstances', value=9999), limit=None)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"query\": \"give me big mushroom dataset.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredQuery(query='mushroom dataset', filter=Comparison(comparator=<Comparator.GTE: 'gte'>, attribute='NumberOfClasses', value=2.0), limit=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"query\": \"give me mushroom dataset with 2 or more classes.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Finding device.\n",
      "[INFO] Device found: cuda\n",
      "[INFO] Loading metadata from file.\n",
      "[INFO] Loading model...\n",
      "[INFO] Model loaded.\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers.self_query.chroma import ChromaTranslator\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "import chromadb\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../backend/\")\n",
    "from backend.modules.utils import load_config_and_device\n",
    "from backend.modules.llm import *\n",
    "\n",
    "config = load_config_and_device(\"../backend/config.json\")\n",
    "config[\"data_dir\"] = \"../data/\"\n",
    "config[\"persist_dir\"] = \"../data/chroma_db/\"\n",
    "\n",
    "vectorstore = chromadb.PersistentClient(path=config[\"persist_dir\"])\n",
    "qa_dataset_handler = QASetup(\n",
    "    config=config,\n",
    "    data_type=\"dataset\",\n",
    "    client=vectorstore,\n",
    ")\n",
    "\n",
    "qa_dataset, _ = qa_dataset_handler.setup_vector_db_and_qa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.query_constructor.base import (\n",
    "    StructuredQueryOutputParser,\n",
    "    get_query_constructor_prompt,\n",
    ")\n",
    "\n",
    "# llm = ChatOllama(model=\"llama3\", temperature=0)\n",
    "# output_parser = StructuredQueryOutputParser.from_components()\n",
    "# query_constructor = prompt | llm | output_parser\n",
    "\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "retriever = SelfQueryRetriever(\n",
    "    query_constructor=chain,\n",
    "    vectorstore=qa_dataset[0].vectorstore,\n",
    "    structured_query_translator=ChromaTranslator(),\n",
    "    verbose=True,\n",
    ")\n",
    "# retriever = qa_dataset.vectorstore.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:11434\n",
      "DEBUG:urllib3.connectionpool:http://localhost:11434 \"POST /api/chat HTTP/1.1\" 200 None\n",
      "INFO:langchain.retrievers.self_query.base:Generated Query: query='mushroom' filter=None limit=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mushroom {}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'did': 43922, 'name': 'mushroom'}, page_content='did - 43922, name - mushroom, version - 3, uploader - 30861, status - active, format - ARFF, MajorityClassSize - 4208.0, MaxNominalAttDistinctValues - nan, MinorityClassSize - 3916.0, NumberOfClasses - 2.0, NumberOfFeatures - 23.0, NumberOfInstances - 8124.0, NumberOfInstancesWithMissingValues - 0.0, NumberOfMissingValues - 0.0, NumberOfNumericFeatures - 0.0, NumberOfSymbolicFeatures - 23.0, description - Mushroom records drawn from The Audubon Society Field Guide to North American Mushrooms (1981). G. H. Lincoff (Pres.), New York: Alfred A. Knopf, qualities - AutoCorrelation : 0.726332635725717, Dimensionality : 0.002831117676021664, MajorityClassPercentage : 51.7971442639094, MajorityClassSize : 4208.0, MinorityClassPercentage : 48.20285573609059, MinorityClassSize : 3916.0, NumberOfBinaryFeatures : 6.0, NumberOfClasses : 2.0, NumberOfFeatures : 23.0, NumberOfInstances : 8124.0, NumberOfInstancesWithMissingValues : 0.0, NumberOfMissingValues : 0.0, NumberOfNumericFeatures : 0.0,'),\n",
       " Document(metadata={'did': 120, 'name': 'BNG(mushroom)'}, page_content='did - 120, name - BNG(mushroom), version - 1, uploader - 1, status - active, format - ARFF, MajorityClassSize - 518298.0, MaxNominalAttDistinctValues - 12.0, MinorityClassSize - 481702.0, NumberOfClasses - 2.0, NumberOfFeatures - 23.0, NumberOfInstances - 1000000.0, NumberOfInstancesWithMissingValues - 0.0, NumberOfMissingValues - 0.0, NumberOfNumericFeatures - 0.0, NumberOfSymbolicFeatures - 23.0, description - None, qualities - AutoCorrelation : 0.5011905011905012, CfsSubsetEval_DecisionStumpAUC : 0.9847860299226502, CfsSubsetEval_DecisionStumpErrRate : 0.021824, CfsSubsetEval_DecisionStumpKappa : 0.9562780842181652, CfsSubsetEval_NaiveBayesAUC : 0.9847860299226502, CfsSubsetEval_NaiveBayesErrRate : 0.021824, CfsSubsetEval_NaiveBayesKappa : 0.9562780842181652, CfsSubsetEval_kNN1NAUC : 0.9847860299226502, CfsSubsetEval_kNN1NErrRate : 0.021824, CfsSubsetEval_kNN1NKappa : 0.9562780842181652, ClassEntropy : 0.9990337071596953, DecisionStumpAUC : 0.8815512935166292, DecisionStumpErrRate :'),\n",
       " Document(metadata={'did': 44272, 'name': 'Meta_Album_FNG_Micro'}, page_content='did - 44272, name - Meta_Album_FNG_Micro, version - 1, uploader - 30980, status - active, format - arff, MajorityClassSize - 40.0, MaxNominalAttDistinctValues - nan, MinorityClassSize - 40.0, NumberOfClasses - 20.0, NumberOfFeatures - 3.0, NumberOfInstances - 800.0, NumberOfInstancesWithMissingValues - 0.0, NumberOfMissingValues - 0.0, NumberOfNumericFeatures - 0.0, NumberOfSymbolicFeatures - 0.0, description - ## **Meta-Album Fungi Dataset (Micro)**\\n***'),\n",
       " Document(metadata={'did': 24, 'name': 'mushroom'}, page_content='did - 24, name - mushroom, version - 1, uploader - 1, status - active, format - ARFF, MajorityClassSize - 4208.0, MaxNominalAttDistinctValues - 12.0, MinorityClassSize - 3916.0, NumberOfClasses - 2.0, NumberOfFeatures - 23.0, NumberOfInstances - 8124.0, NumberOfInstancesWithMissingValues - 2480.0, NumberOfMissingValues - 2480.0, NumberOfNumericFeatures - 0.0, NumberOfSymbolicFeatures - 23.0, description - **Author**: [Jeff Schlimmer](Jeffrey.Schlimmer@a.gp.cs.cmu.edu)  \\n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/mushroom) - 1981     \\n**Please cite**:  The Audubon Society Field Guide to North American Mushrooms (1981). G. H. Lincoff (Pres.), New York: Alfred A. Knopf \\n\\n\\n### Description\\n\\nThis dataset describes mushrooms in terms of their physical characteristics. They are classified into: poisonous or edible.')]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"What are some datasets on mushroom.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:11434\n",
      "DEBUG:urllib3.connectionpool:http://localhost:11434 \"POST /api/chat HTTP/1.1\" 200 None\n",
      "INFO:langchain.retrievers.self_query.base:Generated Query: query='mushroom datasets with greater than 2.0 classes' filter=Comparison(comparator=<Comparator.GT: 'gt'>, attribute='NumberOfClasses', value=2.0) limit=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mushroom datasets with greater than 2.0 classes {'filter': {'NumberOfClasses': {'$gt': 2.0}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"Give mushroom datasets with more than 2 classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:11434\n",
      "DEBUG:urllib3.connectionpool:http://localhost:11434 \"POST /api/chat HTTP/1.1\" 200 None\n"
     ]
    }
   ],
   "source": [
    "structured_query = chain.invoke(\n",
    "    {\"query\": \"give me mushroom dataset with 2 or more classes.\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mushroom dataset\n",
      "comparator=<Comparator.LT: 'lt'> attribute='NumberOfInstances' value=10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('mushroom dataset', {'filter': {'NumberOfInstances': {'$lt': 10000}}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(structured_query.query)\n",
    "print(structured_query.filter)\n",
    "\n",
    "from langchain_community.query_constructors.chroma import ChromaTranslator\n",
    "\n",
    "obj = ChromaTranslator()\n",
    "obj.visit_structured_query(structured_query=structured_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('mushroom dataset',\n",
       " {'filter': [{'range': {'metadata.NumberOfClasses': {'gte': 2.0}}}]})"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.query_constructors.elasticsearch import ElasticsearchTranslator\n",
    "\n",
    "obj = ElasticsearchTranslator()\n",
    "obj.visit_structured_query(structured_query=structured_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k': 30}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_dataset[0].search_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using custom prompts with langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using schema_prompt parameter to append to the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DEFAULT_SCHEMA = \"\"\"\\\n",
    "<< Structured Request Schema >>\n",
    "When responding use a markdown code snippet with a JSON object formatted in the following schema:\n",
    "\n",
    "```json\n",
    "{{{{\n",
    "    \"query\": string \\\\ text string to compare to document contents\n",
    "    \"filter\": string \\\\ logical condition statement for filtering documents\n",
    "}}}}\n",
    "```\n",
    "\n",
    "Please correct the previous output {output} and only output a markdown code snippet.\n",
    "\n",
    "\"\"\"\n",
    "# DEFAULT_SCHEMA_PROMPT = PromptTemplate.from_template(DEFAULT_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = DEFAULT_SCHEMA.format(output = \"hellow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FewShotPromptTemplate(input_variables=['\\n    \"query\"', 'query'], examples=[{'i': 1, 'user_query': 'Give me mushroom datasets with less than 10k rows.', 'structured_request': '{{\\n    \"query\": \"mushroom dataset\",\\n    \"filter\": \"lt(\\\\\"NumberOfInstances\\\\\", 10000)\"\\n}}'}, {'i': 2, 'user_query': 'Give me datasets than can be used in healthcare with 2 or more classes', 'structured_request': '{{\\n    \"query\": \"heathcare dataset \",\\n    \"filter\": \"gte(\\\\\"NumberOfClasses\\\\\", 2.0)\"\\n}}'}, {'i': 3, 'user_query': 'Give me datasets than can be used in healthcare, or climate applications with 2 or more classes and in arff format.', 'structured_request': '{{\\n    \"query\": \"heathcare dataset, climate datasets\",\\n    \"filter\": \"and(gte(\\\\\"NumberOfClasses\\\\\", 2.0), eq(\\\\\"format\\\\\", \\\\\"arff\\\\\"))\"\\n}}'}, {'i': 4, 'user_query': 'Give me medical datasets.', 'structured_request': '{{\\n    \"query\": \"medical datasets\",\\n    \"filter\": \"NO_FILTER\"\\n}}'}, {'i': 5, 'user_query': 'Give me medical datasets with large number of features.', 'structured_request': '{{\\n    \"query\": \"medical datasets\",\\n    \"filter\": \"gte(\\\\\"NumberOfFeatures, 100)\"\\n}}'}], example_prompt=PromptTemplate(input_variables=['i', 'structured_request', 'user_query'], template='<< Example {i}. >>\\nUser Query:\\n{user_query}\\n\\nStructured Request:\\n```json\\n{structured_request}\\n```\\n'), suffix='<< Example 6. >>\\nUser Query:\\n{query}\\n\\nStructured Request:\\n', prefix='Your goal is to structure the user\\'s query to match the request schema provided below.\\n\\n<< Structured Request Schema >>\\nWhen responding use a markdown code snippet with a JSON object formatted in the following schema:\\n\\n```json\\n{\\n    \"query\": string \\\\ text string to compare to document contents\\n    \"filter\": string \\\\ logical condition statement for filtering documents\\n}\\n```\\n\\nPlease correct the previous output hellow and only output a markdown code snippet.\\n\\n\\n\\n<< Data Source >>\\n```json\\n{{\\n    \"content\": \"Metadata of datasets for various machine learning applications fetched from OpenML platform\",\\n    \"attributes\": {{\\n    \"status\": {{\\n        \"description\": \"Current status of the dataset. Whether the dataset is active.\",\\n        \"type\": \"String\"\\n    }},\\n    \"NumberOfClasses\": {{\\n        \"description\": \"Number of classes in the dataset. 2.0 for binary classification, and more than 2.0 for multi-class classification.\",\\n        \"type\": \"Numeric\"\\n    }},\\n    \"NumberOfFeatures\": {{\\n        \"description\": \"Number of features or attributes in the dataset.\",\\n        \"type\": \"Numeric\"\\n    }},\\n    \"NumberOfInstances\": {{\\n        \"description\": \"Number of instances in the dataset\",\\n        \"type\": \"Numeric\"\\n    }},\\n    \"Combined_information\": {{\\n        \"description\": \"Combine information from all the coulmns in the dataset.\",\\n        \"type\": \"String\"\\n    }}\\n}}\\n}}\\n```\\n')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = load_query_constructor_runnable(\n",
    "    ChatOllama(model=\"llama3\"),\n",
    "    document_content_description,\n",
    "    # attribute_info,\n",
    "    filter_attribute_info,\n",
    "    examples=examples,\n",
    "    schema_prompt=schema,\n",
    "    fix_invalid=True,\n",
    ")\n",
    "chain.get_prompts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use completely custom prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttributeInfo = None\n",
    "allowed_comparators = None\n",
    "allowed_operators = None\n",
    "\n",
    "allowed_attributes = []\n",
    "for ainfo in attribute_info:\n",
    "    allowed_attributes.append(\n",
    "        ainfo.name if isinstance(ainfo, AttributeInfo) else ainfo[\"name\"]\n",
    "    )\n",
    "output_parser = StructuredQueryOutputParser.from_components(\n",
    "    allowed_comparators=allowed_comparators,\n",
    "    allowed_operators=allowed_operators,\n",
    "    allowed_attributes=allowed_attributes,\n",
    "    fix_invalid=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.structured_query import (\n",
    "    Comparator,\n",
    "    Operator,\n",
    ")\n",
    "from langchain.chains.query_constructor.base import StructuredQueryOutputParser\n",
    "\n",
    "def create_custom_prompt_template():\n",
    "    prompt_template = (\n",
    "        \"Given the initial extraction: {initial_result}, \"\n",
    "        \"which got the score of {metric},focus on refining the 'query' part.\"\n",
    "        \"Ensure it captures all relevant topics from the question: '{question}'.\"\n",
    "        \"Provide only the refined query. Given the initial extraction: {initial_result}, \"\n",
    "        \"focus on refining the 'filter' part. Ensure it accurately represents all \"\n",
    "        \"conditions from the question: '{question}' .Provide only the refined filter.\"\n",
    "        \"When responding use a markdown code snippet with a JSON object formatted in the following schema:\"\n",
    "        \"\"\" \n",
    "            ```json\n",
    "            {{{{\n",
    "                \"query\": string \\\\ text string to compare to document contents\n",
    "                \"filter\": string \\\\ logical condition statement for filtering documents\n",
    "                \"limit\": int \\\\ the number of documents to retrieve\n",
    "            }}}}\n",
    "            ```\n",
    "        The query string should contain only text that is expected to match the contents of documents. Any conditions in the filter should not be mentioned in the query as well.\n",
    "\n",
    "        A logical condition statement is composed of one or more comparison and logical operation statements.\n",
    "\n",
    "        A comparison statement takes the form: `comp(attr, val)`:\n",
    "        - `comp` ({allowed_comparators}): comparator\n",
    "        - `attr` (string):  name of attribute to apply the comparison to\n",
    "        - `val` (string): is the comparison value\n",
    "\n",
    "        A logical operation statement takes the form `op(statement1, statement2, ...)`:\n",
    "        - `op` ({allowed_operators}): logical operator\n",
    "        - `statement1`, `statement2`, ... (comparison statements or logical operation statements): one or more statements to apply the operation to\n",
    "                \"\"\"\n",
    "    )\n",
    "    return PromptTemplate(\n",
    "        input_variables=[\"initial_result\", \"metric\", \"question\"],\n",
    "        template=prompt_template\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query_structuring_chain_with_custom_prompt(document_content_description, content_attr, model=\"llama3.1\"):\n",
    "    # Filter the attribute info based on content_attr\n",
    "    filter_attribute_info = tuple(ai for ai in attribute_info if ai[\"name\"] in content_attr)\n",
    "    \n",
    "    # Create a custom prompt template\n",
    "    custom_prompt = create_custom_prompt_template()\n",
    "    \n",
    "    # Prepare the input for the custom prompt\n",
    "    attributes = \", \".join([f\"{attr['name']}: {attr['description']}\" for attr in filter_attribute_info])\n",
    "    # examples_formatted = \"\\n\\n\".join([f\"Input: {ex['input']}\\nOutput: {ex['structured_query']}\" for ex in examples])\n",
    "    \n",
    "    # Create a chain with the custom prompt\n",
    "    chain = LLMChain(\n",
    "        llm=ChatOllama(model=model),\n",
    "        prompt=custom_prompt,\n",
    "        output_parser=StructuredQueryOutputParser.from_components(\n",
    "            allowed_comparators=tuple(Comparator),\n",
    "            allowed_operators=tuple(Operator),\n",
    "            allowed_attributes=[attr[\"name\"] for attr in filter_attribute_info],\n",
    "            fix_invalid=True,\n",
    "        )\n",
    "    )\n",
    "    return chain.run({\n",
    "        \"initial_result\": structured_query, \n",
    "        \"metric\": 0.8, \n",
    "        \"question\": \"find some mushroom dataset with less than 10k size and json format\",\n",
    "        \"allowed_comparators\": tuple(Comparator),\n",
    "        \"allowed_operators\": tuple(Operator)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_query_structuring_chain_with_custom_prompt(document_content_description=document_content_description, content_attr=attribute_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredQuery(query='mushroom dataset', filter=Comparison(comparator=<Comparator.LT: 'lt'>, attribute='NumberOfInstances', value=10000), limit=None)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Input to FewShotPromptTemplate is missing variables {\\'\\\\n    \"query\"\\'}.  Expected: [\\'\\\\n    \"query\"\\', \\'query\\'] Received: [\\'query\\', \\'initial_result\\', \\'metric\\', \\'question\\']'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfind some mushroom dataset with less than 10k size and json format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minitial_result\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstructured_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetric\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfind some mushroom dataset with less than 10k size and json format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ai_search/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:2876\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2874\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m   2875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2876\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2877\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2878\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/Documents/ai_search/.venv/lib/python3.12/site-packages/langchain_core/prompts/base.py:179\u001b[0m, in \u001b[0;36mBasePromptTemplate.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags:\n\u001b[1;32m    178\u001b[0m     config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_prompt_with_error_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ai_search/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:1785\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1782\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m   1783\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1784\u001b[0m         Output,\n\u001b[0;32m-> 1785\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1786\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1787\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1788\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1789\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1791\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1792\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1793\u001b[0m     )\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1795\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/Documents/ai_search/.venv/lib/python3.12/site-packages/langchain_core/runnables/config.py:427\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    426\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ai_search/.venv/lib/python3.12/site-packages/langchain_core/prompts/base.py:153\u001b[0m, in \u001b[0;36mBasePromptTemplate._format_prompt_with_error_handling\u001b[0;34m(self, inner_input)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_format_prompt_with_error_handling\u001b[39m(\u001b[38;5;28mself\u001b[39m, inner_input: Dict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PromptValue:\n\u001b[0;32m--> 153\u001b[0m     _inner_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_prompt(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_inner_input)\n",
      "File \u001b[0;32m~/Documents/ai_search/.venv/lib/python3.12/site-packages/langchain_core/prompts/base.py:145\u001b[0m, in \u001b[0;36mBasePromptTemplate._validate_input\u001b[0;34m(self, inner_input)\u001b[0m\n\u001b[1;32m    143\u001b[0m missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_variables)\u001b[38;5;241m.\u001b[39mdifference(inner_input)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is missing variables \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Expected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_variables\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(inner_input\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m     )\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inner_input\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Input to FewShotPromptTemplate is missing variables {\\'\\\\n    \"query\"\\'}.  Expected: [\\'\\\\n    \"query\"\\', \\'query\\'] Received: [\\'query\\', \\'initial_result\\', \\'metric\\', \\'question\\']'"
     ]
    }
   ],
   "source": [
    "chain.invoke({\"query\": \"find some mushroom dataset with less than 10k size and json format\", \"initial_result\": structured_query, \"metric\":0.8, \"question\":\"find some mushroom dataset with less than 10k size and json format\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query_structuring_chain_with_custom_prompt(document_content_description, content_attr, model=\"llama3.1\"):\n",
    "    # Filter the attribute info based on content_attr\n",
    "    filter_attribute_info = tuple(ai for ai in attribute_info if ai[\"name\"] in content_attr)\n",
    "    \n",
    "    # Create a custom prompt template\n",
    "    custom_prompt = create_custom_prompt_template()\n",
    "    \n",
    "    # Prepare the input for the custom prompt\n",
    "    attributes = \", \".join([f\"{attr['name']}: {attr['description']}\" for attr in filter_attribute_info])\n",
    "    # examples_formatted = \"\\n\\n\".join([f\"Input: {ex['input']}\\nOutput: {ex['structured_query']}\" for ex in examples])\n",
    "    \n",
    "    # Create a chain with the custom prompt\n",
    "    chain = LLMChain(\n",
    "        llm=ChatOllama(model=model),\n",
    "        prompt=custom_prompt,\n",
    "        output_parser=StructuredQueryOutputParser.from_components(\n",
    "            allowed_comparators=tuple(Comparator),\n",
    "            allowed_operators=tuple(Operator),\n",
    "            allowed_attributes=[attr[\"name\"] for attr in filter_attribute_info],\n",
    "            fix_invalid=True,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return chain.run({\n",
    "        \"document_contents\": document_content_description,\n",
    "        \"attributes\": attributes,\n",
    "        \"examples\": None\n",
    "    })\n",
    "\n",
    "def validate_and_retry(structured_query_output, model=\"llama3.1\"):\n",
    "    validation_prompt = (\n",
    "        \"Here is a structured query output: {output}\\n\"\n",
    "        \"Please check if it is a valid JSON. If it is verbose or incorrect, fix it.\"\n",
    "    )\n",
    "    \n",
    "    chain = LLMChain(\n",
    "        llm=ChatOllama(model=model),\n",
    "        prompt=PromptTemplate(\n",
    "            input_variables=[\"output\"],\n",
    "            template=validation_prompt\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    valid_output = chain.run({\"output\": structured_query_output})\n",
    "    return valid_output\n",
    "\n",
    "document_description = \"Metadata of machine learning datasets including status, number of classes, number of instances, number of features, and combined information about the dataset.\"\n",
    "content_attributes = [\"status\", \"number_of_classes\", \"combined_information\"]\n",
    "\n",
    "initial_output = create_query_structuring_chain_with_custom_prompt(document_description, content_attributes)\n",
    "print(initial_output)\n",
    "final_output = validate_and_retry(initial_output)\n",
    "print(final_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
