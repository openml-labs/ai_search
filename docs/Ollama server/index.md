# Ollama Server

- This is the server that runs an Ollama server (This is basically an optimized version of a local LLM. It does not do anything of itself but runs as a background service so you can use the LLM). 
- You can start it by running `cd ollama && ./get_ollama.sh &`