{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting an LLM summary using the API\n",
    "- How would you use the API and an LLM model + prompt to generate a summary of the results obtained from the RAG pipeline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain_community.cache import SQLiteCache\n",
    "import os\n",
    "import sys\n",
    "# change the path to the backend directory\n",
    "sys.path.append(os.path.join(os.path.dirname(\".\"), '../../backend/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.llm import get_llm_chain, get_llm_result_from_string\n",
    "from modules.utils import load_config_and_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Finding device.\n",
      "[INFO] Device found: cpu\n"
     ]
    }
   ],
   "source": [
    "# Config and DB\n",
    "\n",
    "# load the configuration and device\n",
    "config = load_config_and_device(\"../../backend/config.json\")\n",
    "config[\"persist_dir\"] = \"../../backend/data/chroma_db/\"\n",
    "config[\"data_dir\"] = \"../../backend/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get LLM summary of a string\n",
    "- Ensure that Ollama is running before this works ```bash ollama/.get_ollama.sh``` (or use the desktop Ollama app for testing)\n",
    "- As you can tell, the data needs to be a string. To then get the results from a bunch of langchain documents, you must first concatenate the text you care about into a single string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"llm_prompt_template\"] = \"The following is a set of documents {docs}. Based on these docs, please summarize the content concisely. Also give a list of main concepts found in the documents. Do not add any new information. Helpful Answer: \"\n",
    "config[\"llm_model\"] = \"qwen2:1.5b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the llm chain and set the cache\n",
    "llm_chain = get_llm_chain(config=config, local=True)\n",
    "# use os path to ensure compatibility with all operating systems\n",
    "set_llm_cache(SQLiteCache(database_path=os.path.join(config[\"data_dir\"], \".langchain.db\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Eating Disorders\\n\\n- Eating disorders refer to psychological and emotional conditions characterized by compulsive behaviors such as overeating or excessive restriction.\\n- These behaviors lead to significant weight loss, malnutrition, and serious health complications.\\n\\nEating Nice Food\\n\\n- This document focuses on the importance of eating good food for maintaining a healthy and balanced diet.\\n- It highlights how selecting nutrient-dense foods can aid in overall physical and mental well-being.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_llm_result_from_string(llm_chain, \"This document is about eating disorders and this one is about eating nice food\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
