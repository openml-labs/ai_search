{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial on changing models\n",
    "- How would you use a different embedding and llm model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from langchain_community.cache import SQLiteCache\n",
    "import os\n",
    "import sys\n",
    "import chromadb\n",
    "\n",
    "# change the path to the backend directory\n",
    "sys.path.append(os.path.join(os.path.dirname(\".\"), \"../../backend/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.utils import load_config_and_device\n",
    "from modules.llm import setup_vector_db_and_qa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Finding device.\n",
      "[INFO] Device found: cpu\n",
      "{'rqa_prompt_template': 'This database is a list of metadata. Use the following pieces of context to find the relevant document. Answer only from the context given using the {question} given. If you do not know the answer, say you do not know. {context}', 'llm_prompt_template': 'The following is a set of documents {docs}. Based on these docs, please summarize the content concisely. Also give a list of main concepts found in the documents. Do not add any new information. Helpful Answer: ', 'num_return_documents': 50, 'embedding_model': 'BAAI/bge-large-en-v1.5', 'llm_model': 'qwen2:1.5b', 'num_documents_for_llm': 10, 'data_dir': '../backend/data/', 'persist_dir': '../backend/data/chroma_db/', 'testing_flag': False, 'ignore_downloading_data': False, 'test_subset': False, 'data_download_n_jobs': 20, 'training': True, 'temperature': 0.95, 'top_p': 0.95, 'search_type': 'similarity', 'reranking': False, 'long_context_reorder': False, 'device': 'cpu', 'type_of_data': 'dataset'}\n"
     ]
    }
   ],
   "source": [
    "config = load_config_and_device(\"../../backend/config.json\")\n",
    "config[\"persist_dir\"] = \"../backend/data/chroma_db/\"\n",
    "config[\"data_dir\"] = \"../backend/data/\"\n",
    "config[\"type_of_data\"] = \"dataset\"\n",
    "config[\"training\"] = True\n",
    "# load the persistent database using ChromaDB\n",
    "client = chromadb.PersistentClient(path=config[\"persist_dir\"])\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding model\n",
    "- Pick a model from HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"embedding_model\"] = \"HuggingFaceH4/capybara\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pick a model from Ollama - https://ollama.com/library?sort=popular\n",
    "- eg : mistral\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"llm_model\"] = \"mistral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = setup_vector_db_and_qa(\n",
    "    config=config, data_type=config[\"type_of_data\"], client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTANT\n",
    "- Do NOT forget to change the model to the best model in ollama/get_ollama.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
