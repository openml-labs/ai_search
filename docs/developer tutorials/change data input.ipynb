{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain_community.cache import SQLiteCache\n",
    "import os\n",
    "import sys\n",
    "import chromadb\n",
    "\n",
    "# change the path to the backend directory\n",
    "sys.path.append(os.path.join(os.path.dirname(\".\"), \"../../backend/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.utils import *\n",
    "from modules.rag_llm import *\n",
    "from modules.results_gen import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Finding device.\n",
      "[INFO] Device found: mps\n",
      "{'rqa_prompt_template': 'This database is a list of metadata. Use the following pieces of context to find the relevant document. Answer only from the context given using the {question} given. If you do not know the answer, say you do not know. {context}', 'llm_prompt_template': 'The following is a set of documents {docs}. Based on these docs, please summarize the content concisely. Also give a list of main concepts found in the documents. Do not add any new information. Helpful Answer: ', 'num_return_documents': 30, 'embedding_model': 'BAAI/bge-large-en-v1.5', 'llm_model': 'llama3', 'num_documents_for_llm': 30, 'data_dir': '../data/doc_examples/', 'persist_dir': '../data/doc_examples/chroma_db/', 'testing_flag': True, 'ignore_downloading_data': False, 'test_subset': True, 'data_download_n_jobs': 20, 'training': False, 'temperature': 0.95, 'top_p': 0.95, 'search_type': 'similarity', 'reranking': False, 'long_context_reorder': False, 'structure_query': False, 'use_chroma_for_saving_metadata': False, 'device': 'mps', 'type_of_data': 'dataset'}\n"
     ]
    }
   ],
   "source": [
    "config = load_config_and_device(\"../../backend/config.json\")\n",
    "config[\"persist_dir\"] = \"../data/doc_examples/chroma_db/\"\n",
    "config[\"data_dir\"] = \"../data/doc_examples/\"\n",
    "config[\"type_of_data\"] = \"dataset\"\n",
    "config[\"training\"] = False\n",
    "config[\"testing_flag\"] = True #set this to false while training, this is for demo\n",
    "config[\"test_subset\"] = True #set this to false while training, this is for demo\n",
    "\n",
    "# load the persistent database using ChromaDB\n",
    "client = chromadb.PersistentClient(path=config[\"persist_dir\"])\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change the way the data is combined\n",
    "- To pass to the RAG, all the metadata is combined into a single string. This is done by concatenating all the metadata fields with a space separator.\n",
    "- We can change the way the data in whatever way we want. For example, we can concatenate all the metadata fields with a \"~\" separator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_attributes(attribute: object, attr_name: str) -> str:\n",
    "        \"\"\"\n",
    "        Description: Join the attributes of the OpenML objects into a single string with the format \"key : value\"\n",
    "        \"\"\"\n",
    "        return (\n",
    "            \" ~ \".join(\n",
    "                [f\"{k} : {v},\" for k, v in getattr(attribute, attr_name, {}).items()]\n",
    "            )\n",
    "            if hasattr(attribute, attr_name)\n",
    "            else \"\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "OpenMLObjectHandler.join_attributes = join_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup llm chain, initialize the retriever and llm, and setup Retrieval QA\n",
    "qa_dataset_handler = QASetup(\n",
    "    config=config,\n",
    "    data_type=config[\"type_of_data\"],\n",
    "    client=client,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_dataset, _ = qa_dataset_handler.setup_vector_db_and_qa()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
