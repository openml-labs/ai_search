{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain_community.cache import SQLiteCache\n",
    "import os\n",
    "import sys\n",
    "import chromadb\n",
    "# change the path to the backend directory\n",
    "sys.path.append(os.path.join(os.path.dirname(\".\"), '../../backend/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.utils import get_all_metadata_from_openml, create_metadata_dataframe, load_config_and_device\n",
    "from modules.llm import load_document_and_create_vector_store, setup_vector_db_and_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Finding device.\n",
      "[INFO] Device found: cpu\n",
      "{'rqa_prompt_template': 'This database is a list of metadata. Use the following pieces of context to find the relevant document. Answer only from the context given using the {question} given. If you do not know the answer, say you do not know. {context}', 'llm_prompt_template': 'The following is a set of documents {docs}. Based on these docs, please summarize the content concisely. Also give a list of main concepts found in the documents. Do not add any new information. Helpful Answer: ', 'num_return_documents': 50, 'embedding_model': 'BAAI/bge-large-en-v1.5', 'llm_model': 'qwen2:1.5b', 'num_documents_for_llm': 10, 'data_dir': '../backend/data/', 'persist_dir': '../backend/data/chroma_db/', 'testing_flag': False, 'ignore_downloading_data': False, 'test_subset_2000': False, 'data_download_n_jobs': 20, 'training': True, 'temperature': 0.95, 'top_p': 0.95, 'search_type': 'similarity', 'reranking': False, 'long_context_reorder': False, 'device': 'cpu', 'type_of_data': 'dataset'}\n"
     ]
    }
   ],
   "source": [
    "config = load_config_and_device(\"../../backend/config.json\")\n",
    "config[\"persist_dir\"] = \"../backend/data/chroma_db/\"\n",
    "config[\"data_dir\"] = \"../backend/data/\"\n",
    "config[\"type_of_data\"] = \"dataset\"\n",
    "config[\"training\"] = True\n",
    "\n",
    "# load the persistent database using ChromaDB\n",
    "client = chromadb.PersistentClient(path=config[\"persist_dir\"])\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Download the data if it does not exist\n",
    "openml_data_object, data_id, all_metadata = get_all_metadata_from_openml(\n",
    "    config=config\n",
    ")\n",
    "# Create the combined metadata dataframe\n",
    "metadata_df, all_metadata = create_metadata_dataframe(\n",
    "    openml_data_object, data_id, all_metadata, config=config\n",
    ")\n",
    "# Create the vector store\n",
    "vectordb = load_document_and_create_vector_store(\n",
    "    metadata_df, config=config, chroma_client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = setup_vector_db_and_qa(\n",
    "        config=config, data_type=config[\"type_of_data\"], client=client\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
