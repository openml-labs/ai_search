{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain_community.cache import SQLiteCache\n",
    "import os\n",
    "import sys\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/smukherjee/.pyenv/versions/3.10.14/envs/openml/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from backend.modules.utils import *\n",
    "from backend.modules.rag_llm import *\n",
    "from backend.modules.results_gen import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Finding device.\n",
      "[INFO] Device found: mps\n",
      "{'rqa_prompt_template': 'This database is a list of metadata. Use the following pieces of context to find the relevant document. Answer only from the context given using the {question} given. If you do not know the answer, say you do not know. {context}', 'llm_prompt_template': 'The following is a set of documents {docs}. Based on these docs, please summarize the content concisely. Also give a list of main concepts found in the documents. Do not add any new information. Helpful Answer: ', 'num_return_documents': 30, 'embedding_model': 'BAAI/bge-large-en-v1.5', 'llm_model': 'llama3', 'num_documents_for_llm': 30, 'data_dir': '../../data/doc_examples/', 'persist_dir': '../../data/doc_examples/chroma_db/', 'testing_flag': True, 'ignore_downloading_data': False, 'test_subset': True, 'data_download_n_jobs': 20, 'training': False, 'temperature': 0.95, 'top_p': 0.95, 'search_type': 'similarity', 'reranking': False, 'long_context_reorder': False, 'structure_query': False, 'use_chroma_for_saving_metadata': False, 'device': 'mps', 'type_of_data': 'dataset'}\n"
     ]
    }
   ],
   "source": [
    "config = load_config_and_device(\"../../../backend/config.json\")\n",
    "config[\"persist_dir\"] = \"../../data/doc_examples/chroma_db/\"\n",
    "config[\"data_dir\"] = \"../../data/doc_examples/\"\n",
    "config[\"type_of_data\"] = \"dataset\"\n",
    "config[\"training\"] = False\n",
    "config[\"testing_flag\"] = True  # set this to false while training, this is for demo\n",
    "config[\"test_subset\"] = True  # set this to false while training, this is for demo\n",
    "\n",
    "# load the persistent database using ChromaDB\n",
    "client = chromadb.PersistentClient(path=config[\"persist_dir\"])\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change the way the data is combined\n",
    "- To pass to the RAG, all the metadata is combined into a single string. This is done by concatenating all the metadata fields with a space separator.\n",
    "- We can change the way the data in whatever way we want. For example, we can concatenate all the metadata fields with a \"~\" separator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_attributes(attribute: object, attr_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Description: Join the attributes of the OpenML objects into a single string with the format \"key : value\"\n",
    "    \"\"\"\n",
    "    return (\n",
    "        \" ~ \".join(\n",
    "            [f\"{k} : {v},\" for k, v in getattr(attribute, attr_name, {}).items()]\n",
    "        )\n",
    "        if hasattr(attribute, attr_name)\n",
    "        else \"\"\n",
    "    )\n",
    "\n",
    "\n",
    "def combine_metadata(\n",
    "    self, all_dataset_metadata: pd.DataFrame, all_data_description_df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Description: Combine the descriptions with the metadata table.\n",
    "    \"\"\"\n",
    "    all_dataset_metadata = pd.merge(\n",
    "        all_dataset_metadata, all_data_description_df, on=\"did\", how=\"inner\"\n",
    "    )\n",
    "    all_dataset_metadata[\"Combined_information\"] = all_dataset_metadata.apply(\n",
    "        self.merge_all_columns_to_string, axis=1\n",
    "    )\n",
    "    return all_dataset_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OpenMLObjectHandler.join_attributes = join_attributes\n",
    "OpenMLObjectHandler.combine_metadata = combine_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup llm chain, initialize the retriever and llm, and setup Retrieval QA\n",
    "qa_dataset_handler = QASetup(\n",
    "    config=config,\n",
    "    data_type=config[\"type_of_data\"],\n",
    "    client=client,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_dataset, _ = qa_dataset_handler.setup_vector_db_and_qa()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
